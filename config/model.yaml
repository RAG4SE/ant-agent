# Model configuration
model_provider: deepseek
model: deepseek-chat
max_tokens: 4096
temperature: 0.5
top_p: 1.0
top_k: 0
max_retries: 10
parallel_tool_calls: true